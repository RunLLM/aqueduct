{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493e3662",
   "metadata": {},
   "source": [
    "## Fine Tuning ResNet with Aqueduct\n",
    "\n",
    "In this notebook, we'll use Tensorflow's pre-built Keras model and fine tune it to detect the difference between comuflage clothes and regular clothes. This example is inpsired by [this blog post](https://pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/) from `pyimagesearch`.\n",
    "\n",
    "Note that this notebook makes two assumptions: \n",
    "1. You have your Aqueduct server connected to a Kubernetes cluster with a GPU node group enabled. The easiest way to set this up is to use a hosted Kubernetes offering like AWS EKS or GKE. See [our documentation](https://docs.aqueducthq.com/integrations/compute-systems/kubernetes) for more details on connecting Aqueduct to Kubernetes.\n",
    "2. You have an object store (e.g., AWS S3) connected with the dataset from the above blog post stored in it. \n",
    "\n",
    "We'll start by creating an Aqueduct client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e691a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aqueduct as aq\n",
    "from aqueduct import op, metric\n",
    "\n",
    "K8S_RESOURCE_NAME = 'eks-us-east-2' # REPLACE ME!\n",
    "\n",
    "client = aq.Client()\n",
    "\n",
    "# This line sets Aqueduct to run in lazy mode, since some of our compute can be expensive,\n",
    "# and it sets all functions to run on the EKS cluster we've connected to.\n",
    "aq.global_config({\"lazy\": True, \"engine\": K8S_RESOURCE_NAME})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23893301",
   "metadata": {},
   "source": [
    "Next, we'll load a connection to our S3 bucket that has our datasets and use Aqueduct's API to retrieve a pointer to our dataset in that S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e51cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_BUCKET_NAME = 'datasets' # REPLACE ME!\n",
    "DATASET_PATH = 'resnet-data/resnet.zip' # REPLACE ME!\n",
    "\n",
    "datasets = client.resource(DATASET_BUCKET_NAME)\n",
    "\n",
    "# Due to the way S3 works, it's more efficient for us to load a large zipped file \n",
    "# rather than many small files. As a result, we load a zipfile.\n",
    "dataset = datasets.file(filepaths=DATASET_PATH, artifact_type='bytes')\n",
    "\n",
    "# Our dataset has two classes, for camouflage clothes and regular clothes.\n",
    "CLASSES = [\"camouflage_clothes\", \"normal_clothes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff4d38",
   "metadata": {},
   "source": [
    "Now that we have our data, we can define an Aqueduct operator that is going to fine-tune ResNet. This code is mostly adapted from the blog post linked above. \n",
    "\n",
    "Roughly, this function: \n",
    "1. Loads in the dataset and prepares it for iteration. \n",
    "2. Loads in the ResNet model and adds layers for fine-tuning.\n",
    "3. Fine-tunes the model for a configurable number of epochs. \n",
    "4. Returns the model. \n",
    "\n",
    "The `@op` decorator allows us to tell Aqueduct that we want this function to have 15GB of RAM and also to have a GPU. In the code below, we use Tensorflow to run the fine-tuning algorithm on the GPU.\n",
    "\n",
    "You'll notice that, in additon to the dataset, `fine_tune_resnet` takes in a number of other parameters: `batch_size`, `num_epochs`, and `init_lr`. Aqueduct can automatically create parameters for you, which we'll see when we call `fine_tune_resnet` below, and we can also create parameters that are shared across functions. \n",
    "\n",
    "In this case, we'll want to use the same `batch_size` for fine-tuning and evaluation, so we'll first define a parmater for the `batch_size` with a default value of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab18264",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = client.create_param('batch_size', default=32)\n",
    "\n",
    "@op(\n",
    "    engine='eks-us-east-2',\n",
    "    resources={\n",
    "        'memory': '15GB',\n",
    "        'gpu_resource_name': 'nvidia.com/gpu',\n",
    "    },\n",
    "    requirements=['tensorflow'],\n",
    ")\n",
    "def fine_tune_resnet(dataset, batch_size, num_epochs, init_lr):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.optimizers.legacy import Adam # Note this model uses a legacy version of the Adam optimizer.\n",
    "    from tensorflow.keras.applications import ResNet50\n",
    "    \n",
    "    import zipfile\n",
    "    import os\n",
    "    import numpy as np\n",
    "    \n",
    "    # Write the zipfile to disk and unzip it. The ImageDataGenerator package from TensorFlow only \n",
    "    # recognizes files on disk.\n",
    "    with open('resnet-data-test.zip', 'wb') as f:\n",
    "        f.write(dataset)\n",
    "    \n",
    "    with zipfile.ZipFile('resnet-data-test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "\n",
    "    train_path = 'resnet-data/training'\n",
    "    val_path = 'resnet-data/validation'\n",
    "    \n",
    "    total_train = len(\n",
    "        os.listdir(os.path.join(train_path, 'normal_clothes'))\n",
    "    ) + len(\n",
    "        os.listdir(os.path.join(train_path, 'camouflage_clothes'))\n",
    "    )\n",
    "    \n",
    "    total_val = len(\n",
    "        os.listdir(os.path.join(val_path, 'normal_clothes'))\n",
    "    ) + len(\n",
    "        os.listdir(os.path.join(val_path, 'camouflage_clothes'))\n",
    "    )\n",
    "\n",
    "    # Run the following code on a GPU.\n",
    "    with tf.device('/GPU:0'):\n",
    "        # Initialize the training data augmentation object with some \n",
    "        # pre-defined parameters.\n",
    "        trainAug = ImageDataGenerator(\n",
    "            rotation_range=25,\n",
    "            zoom_range=0.1,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\"\n",
    "        )\n",
    "\n",
    "        # Initialize the validation data augmentation object, which\n",
    "        # we'll be add mean subtraction to below.\n",
    "        valAug = ImageDataGenerator()\n",
    "\n",
    "        # Define the ImageNet mean subtraction (in RGB order) and set the\n",
    "        # the mean subtraction value for each of the data augmentation\n",
    "        # objects.\n",
    "        mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "        trainAug.mean = mean\n",
    "        valAug.mean = mean\n",
    "\n",
    "        # Use our augmentation objects to create the data generators that will \n",
    "        # allow us to iterate over our training and validation data.\n",
    "        trainGen = trainAug.flow_from_directory(\n",
    "            train_path,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=(224, 224),\n",
    "            color_mode=\"rgb\",\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        valGen = valAug.flow_from_directory(\n",
    "            val_path,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=(224, 224),\n",
    "            color_mode=\"rgb\",\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Load the base model from the Keras ResNet50 implementation.\n",
    "        baseModel = ResNet50(\n",
    "            weights=\"imagenet\", \n",
    "            include_top=False,\n",
    "            input_tensor=Input(shape=(224, 224, 3))\n",
    "        )\n",
    "\n",
    "        # Construct the head of the model that will be placed on top of the\n",
    "        # the base model.\n",
    "        headModel = baseModel.output\n",
    "        headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "        headModel = Flatten(name=\"flatten\")(headModel)\n",
    "        headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "        headModel = Dropout(0.5)(headModel)\n",
    "        headModel = Dense(len(CLASSES), activation=\"softmax\")(headModel)\n",
    "\n",
    "        # Place the head FC model on top of the base model. This will become\n",
    "        # the actual model we will train.\n",
    "        model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "        # Loop over all layers in the base model and freeze them so they will\n",
    "        # *not* be updated during the training process.\n",
    "        for layer in baseModel.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Initialize our optimizer, compile the model, and train the model.\n",
    "        opt = Adam(lr=init_lr, decay=init_lr / num_epochs)\n",
    "        model.compile(\n",
    "            loss=\"binary_crossentropy\", \n",
    "            optimizer=opt,\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        H = model.fit_generator(\n",
    "            trainGen,\n",
    "            steps_per_epoch=total_train // batch_size,\n",
    "            validation_data=valGen,\n",
    "            validation_steps=total_val // batch_size,\n",
    "            epochs=num_epochs\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e821b",
   "metadata": {},
   "source": [
    "Now that we've defined our fine-tuning function, we can call it. Let's look at the arguments to this function:\n",
    "1. `dataset` is defined above as a pointer to the dataset that lives in S3. \n",
    "2. `batch_size` is the parameter that we defined above that will be shared between this function and the next.\n",
    "3. `num_epochs` determines for how many epochs we train the model; we can simply pass in 1, and Aqueduct will convert it to a parameter for us. \n",
    "4. `init_lr` is our initial leraning rate; again Aqueduct automatically turns it into a parameter for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a05a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fine_tune_resnet(dataset, batch_size, 1, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd7e6c",
   "metadata": {},
   "source": [
    "Finally, we're going to define a function that calculates the accuracy of the model we've trained on the testing data in our original dataset. This function is going to take in a pointer to the model we just saved as well as the dataset and our `batch_size` parameter and return an accuracy score for the model we just fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op(\n",
    "    resources={\n",
    "        'memory': '15GB',\n",
    "        'gpu_resource_name': 'nvidia.com/gpu',\n",
    "    },\n",
    "    requirements=['tensorflow']\n",
    ")\n",
    "def calculate_accuracy(model, dataset, batch_size): \n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    import zipfile\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    # Write the zipfile to disk and unzip it. The ImageDataGenerator package from TensorFlow only \n",
    "    # recognizes files on disk or in a DataFrame.\n",
    "    with open('resnet-data-test.zip', 'wb') as f:\n",
    "        f.write(dataset)\n",
    "    \n",
    "    with zipfile.ZipFile('resnet-data-test.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "\n",
    "    # For this run, we only load the testing data.\n",
    "    test_path = 'resnet-data/testing'\n",
    "    total_test = len(\n",
    "        os.listdir(os.path.join(test_path, 'normal_clothes'))\n",
    "    ) + len(\n",
    "        os.listdir(os.path.join(test_path, 'camouflage_clothes'))\n",
    "    )\n",
    "    \n",
    "    with tf.device('/GPU:0'):\n",
    "        # Initialize the testing data augmentation object, which\n",
    "        # we'll add mean subtraction to.\n",
    "        valAug = ImageDataGenerator()\n",
    "\n",
    "        # Define the ImageNet mean subtraction (in RGB order) and set the\n",
    "        # the mean subtraction value for each of the data augmentation\n",
    "        # objects.\n",
    "        valAug.mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "\n",
    "        testGen = valAug.flow_from_directory(\n",
    "            test_path,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=(224, 224),\n",
    "            color_mode=\"rgb\",\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Generate predictions for each of the images in our testing set.\n",
    "        predIdxs = model.predict_generator(\n",
    "            testGen,\n",
    "            steps=(total_test // batch_size) + 1\n",
    "        )\n",
    "\n",
    "        # For each image in the testing set we need to find the index of the\n",
    "        # label with corresponding largest predicted probability.\n",
    "        predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "    # Use SKLearn to generate a classification report and return its accuracy score.\n",
    "    res = classification_report(\n",
    "        testGen.classes, \n",
    "        predIdxs,\n",
    "        target_names=testGen.class_indices.keys(),\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    return res['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd1bae1",
   "metadata": {},
   "source": [
    "We can calculate our accuracy score and see the result right here in our notebook. Since we're fine-tuning the model, running this pipeline will take us about 7-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da474c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(model, dataset, batch_size)\n",
    "\n",
    "accuracy.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014626f3",
   "metadata": {},
   "source": [
    "Finally, we can publish this workflow to Aqueduct. All we need to do is give our workflow a name, and send it off to the Aqueduct server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745670ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "datasets.save(model, \"resnet-finetune.model\")\n",
    "\n",
    "client.publish_flow(\n",
    "    \"Fine-Tune ImageNet\",\n",
    "    dedent(\"\"\"\n",
    "    Fine-tune Tensorflow's ResNet-50 model to differentiate camouflage clothes from regular clothes.\n",
    "    \"\"\"),\n",
    "    artifacts=[model, accuracy],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
