{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6809970",
   "metadata": {},
   "source": [
    "# Predict Missing Wine Ratings Using Pyspark\n",
    "\n",
    "In this demo, we train and use multiple models to impute missing values.  We start with a dataset of wines consisting of key features like acidity. Some of the records are missing feature values. In addition, wine quality scores are given to some but not all of the wines. \n",
    "\n",
    "We will build a workflow that trains a linear model to impute the missing features from the other features and then train a decision tree model to rate the un-rated wines using the imputed features. \n",
    "\n",
    "**Throughout this notebook, you'll see a decorator (`@aq.op`) above functions. This decorator allows Aqueduct to run your functions as a part of a workflow automatically.**\n",
    "\n",
    "**To run this notebook, you will have to connect the following integrations:**\n",
    "- A Databricks or Spark integration\n",
    "- A data integration (ie Snowflake)\n",
    "- S3 (must also be used as metadata store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c16e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aqueduct\n",
    "from aqueduct.decorator import op, check, metric\n",
    "\n",
    "# You can use `localhost` if you're running this notebook on the same machine as the server.\n",
    "# If you're running your notebook on a separate machine from your\n",
    "# Aqueduct server, change this to the address of your Aqueduct server.\n",
    "address = \"http://localhost:8080\"\n",
    "\n",
    "# If you're running youre notebook on a separate machine from your\n",
    "# Aqueduct server, you will have to copy your API key here rather than\n",
    "# using `get_apikey()`.\n",
    "api_key = aqueduct.get_apikey()\n",
    "client = aqueduct.Client(api_key, address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqueduct.global_config({'engine': '<spark or databricks integration>', 'lazy': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f0ada3",
   "metadata": {},
   "source": [
    "## Getting the Data \n",
    "\n",
    "In this demo, we will use the wine table in a snowflake data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19056625",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_warehouse = client.integration(\"<snowflake integration>\")\n",
    "wine_table = snowflake_warehouse.sql(\"select * from wine;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070646d1",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "There are some missing values in the residula sugar column that we need to clean.  Here we will replace the residual sugar with a value predicted by other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbfcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op()\n",
    "def fix_residual_sugar(df):\n",
    "    \"\"\"\n",
    "    This function takes in a DataFrame representing wines data and cleans\n",
    "    the DataFrame by replacing any missing values in the `residual_sugar`\n",
    "    column with the values that would be predicted based on the other columns.\n",
    "    \"\"\"\n",
    "    from pyspark.ml.feature import VectorAssembler\n",
    "    from pyspark.ml.regression import LinearRegression\n",
    "    from pyspark.sql.functions import col, when\n",
    "    from pyspark.sql.types import FloatType\n",
    "\n",
    "    # Convert residual_sugar back to numeric values with missing values as NaN\n",
    "    df = df.withColumn(\"RESIDUAL_SUGAR\", col(\"RESIDUAL_SUGAR\").cast(FloatType()))\n",
    "    print(\"missing residual sugar values:\", df.filter(col(\"RESIDUAL_SUGAR\").isNull()).count())\n",
    "\n",
    "    # Filter out non-numeric columns\n",
    "    numeric_cols = [col for col in df.columns if col not in [\"QUALITY\", \"RESIDUAL_SUGAR\", \"ID\"]\n",
    "                    and df.select(col).dtypes[0][1] in ['double', 'float']]\n",
    "    # Fit a LinearRegression model on the other numeric columns\n",
    "    assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"FEATURES\")\n",
    "    df = assembler.transform(df)\n",
    "\n",
    "    lr = LinearRegression(featuresCol=\"FEATURES\", labelCol=\"RESIDUAL_SUGAR\")\n",
    "    training_df = df.filter(col(\"RESIDUAL_SUGAR\").isNotNull())\n",
    "    model = lr.fit(training_df)\n",
    "\n",
    "    # Use the trained model to predict the missing values of `residual_sugar`\n",
    "    predicted_sugar = model.transform(df.filter(col(\"RESIDUAL_SUGAR\").isNull())).select(\"ID\", \"PREDICTION\")\n",
    "\n",
    "    # Replace the NaN values with the predicted values\n",
    "    df = df.join(predicted_sugar, \"ID\", \"left_outer\").withColumnRenamed(\"PREDICTION\", \"PREDICTED_SUGAR\")\n",
    "    df = df.withColumn(\"RESIDUAL_SUGAR\", \n",
    "                       when(col(\"RESIDUAL_SUGAR\").isNull(), col(\"PREDICTED_SUGAR\"))\n",
    "                       .otherwise(col(\"RESIDUAL_SUGAR\")))\\\n",
    "            .drop(\"PREDICTED_SUGAR\")\n",
    "    print(\"missing residual sugar values after prediction:\", df.filter(col(\"RESIDUAL_SUGAR\").isNull()).count())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_cleaned = fix_residual_sugar(wine_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b06c4",
   "metadata": {},
   "source": [
    "## Tracking number of a Labeled wines \n",
    "\n",
    "As a sanity check, we want to make sure there are enough wines with quality scores to render reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metric()\n",
    "def get_number_labeled_wines(df):\n",
    "    from pyspark.sql.functions import col, sqrt\n",
    "    \"\"\"\n",
    "    This function takes in a DataFrame of wine data and returns\n",
    "    how many wines are missing a quality value. This function is based\n",
    "    on the assumption that missing values are encoded as `\\\\N` in the\n",
    "    underlying DataFrame. The typical, non-null value is expected to\n",
    "    be numeric.\n",
    "    \"\"\"\n",
    "    return df.filter(col(\"QUALITY\").isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70194d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labeled = get_number_labeled_wines(wines_cleaned)\n",
    "num_labeled.bound(lower=1000, severity=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f637d36",
   "metadata": {},
   "source": [
    "## Predicting the Quality of Wines\n",
    "\n",
    "In the following operator we:\n",
    "1. Fit a decision tree model to the wines that do have quality ratings\n",
    "2. Make quality rating predictions for all the wines in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbe7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op()\n",
    "def predict_quality(df):\n",
    "    \"\"\"\n",
    "    This function takes in data about wines and fills in any missing\n",
    "    values for the wine quality by building a machine learning model\n",
    "    that predicts the quality of the wine itself. The expectation for\n",
    "    this function is that many or most of the wines will already be labeled\n",
    "    with their quality. This function uses the existing wine quality\n",
    "    labels as guidance to train its model and fills in missing\n",
    "    values with the model.\n",
    "\n",
    "    Under the hood, this function uses sklearn's DecisionTreeRegressor\n",
    "    model to predict the missing wines' qualities.\n",
    "    \"\"\"\n",
    "    from pyspark.ml.feature import VectorAssembler\n",
    "    from pyspark.ml.regression import DecisionTreeRegressor\n",
    "    from pyspark.sql.functions import col\n",
    "    from pyspark.sql.types import DoubleType\n",
    "\n",
    "    # Convert the quality column to numerica and replace the \"\\N\" with NaN\n",
    "    df = df.withColumn(\"QUALITY\", col(\"QUALITY\").cast(DoubleType()))\n",
    "    print(\"missing quality values:\", df.filter(col(\"quality\").isNull()).count())\n",
    "\n",
    "    # Filter out non-numeric columns\n",
    "    numeric_cols = [col for col in df.columns if col not in [\"QUALITY\", \"ID\"]\n",
    "                    and df.select(col).dtypes[0][1] in ['double', 'float']]\n",
    "\n",
    "    # Fit a model to the columns that are of numerical types but aren't the wine's ID or the quality that we're predicting\n",
    "    assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"QUALITY_FEATURES\")\n",
    "    df = assembler.transform(df)\n",
    "    dt = DecisionTreeRegressor(featuresCol=\"QUALITY_FEATURES\", labelCol=\"QUALITY\", maxDepth=3)\n",
    "    training_df = df.filter(col(\"QUALITY\").isNotNull())\n",
    "    model = dt.fit(training_df)\n",
    "\n",
    "    # Add a `pred_quality` column with the predicted quality for each wine\n",
    "    df = model.transform(df).withColumnRenamed(\"PREDICTION\", \"PRED_QUALITY\")\n",
    "    \n",
    "    return df.drop(\"QUALITY_FEATURES\", \"FEATURES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_quality = predict_quality(wines_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e695d",
   "metadata": {},
   "source": [
    "## Checking Our Predictions\n",
    "\n",
    "As a sanity check, we also verify that the wine quality predictions are reasonable. We'll do this by defining another `metric` on the `predicted_quality` table that calculates the RMSE of the predictions for the wines for which we have actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad998af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metric()\n",
    "def get_rmse(df):\n",
    "    \"\"\"\n",
    "    This metric function takes in a DataFrame and assumes it has two columns,\n",
    "    `quality` and `pred_quality`. It uses numpy to calculate the root mean squared\n",
    "    error of the predicted quality column. It ignores any rows for which the quality\n",
    "    column does not have a valid value.\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import col, sqrt\n",
    "    from pyspark.sql.types import FloatType\n",
    "\n",
    "    # Compute the RMSE between the \"quality\" and \"pred_quality\" columns\n",
    "    residuals = df.select(sqrt(((col(\"QUALITY\") - col(\"PRED_QUALITY\")) ** 2)).alias(\"RESIDUAL\")).dropna()\n",
    "    rmse = residuals.agg({\"RESIDUAL\": \"mean\"}).withColumnRenamed(\"avg(RESIDUAL)\", \"rmse\").select(\"rmse\").first()[0]\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c93410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = get_rmse(predicted_quality)\n",
    "rmse.bound(upper=1.0)\n",
    "rmse.bound(upper=3.0, severity=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054eca42",
   "metadata": {},
   "source": [
    "## Saving the Predicted Wine Quality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_warehouse.save(predicted_quality, table_name=\"pred_wine_quality\", update_mode=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7f990",
   "metadata": {},
   "source": [
    "## Schedule Workflow to Run Daily\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "client.publish_flow(\n",
    "    \"WineRating\",\n",
    "    dedent(\n",
    "        \"\"\"\n",
    "        This workflow builds a model to predict missing ratings for wines \n",
    "        and then uses that model to fill in missing ratings.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    schedule=aqueduct.daily(),\n",
    "    artifacts=[predicted_quality, rmse, num_labeled],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d1cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
